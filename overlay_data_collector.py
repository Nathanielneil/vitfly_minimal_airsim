#!/usr/bin/env python3
"""
è¦†ç›–æ˜¾ç¤ºæ•°æ®æ”¶é›†å™¨
åœ¨AirSimçª—å£å†…æ˜¾ç¤ºæ§åˆ¶ä¿¡æ¯ï¼Œæ— éœ€åˆ‡æ¢çª—å£
"""

import airsim
import numpy as np
import cv2
import time
import os
import pandas as pd
import threading
from pathlib import Path
import queue


class OverlayDataCollector:
    """è¦†ç›–æ˜¾ç¤ºæ•°æ®æ”¶é›†å™¨"""
    
    def __init__(self, data_dir="./training_data"):
        self.client = airsim.MultirotorClient()
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(exist_ok=True)
        
        # æ”¶é›†å‚æ•°
        self.collection_frequency = 10
        self.image_size = (60, 90)
        self.display_size = (400, 300)
        
        # çŠ¶æ€
        self.is_collecting = False
        self.current_trajectory = []
        self.trajectory_count = 0
        self.is_connected = False
        self.running = True
        
        # æ˜¾ç¤ºçª—å£
        self.window_name = "ViTæ•°æ®æ”¶é›†å™¨"
        cv2.namedWindow(self.window_name, cv2.WINDOW_NORMAL)
        cv2.resizeWindow(self.window_name, 500, 400)
        
        # æ§åˆ¶é˜Ÿåˆ—
        self.command_queue = queue.Queue()
        
        print("è¦†ç›–æ˜¾ç¤ºæ•°æ®æ”¶é›†å™¨åˆå§‹åŒ–å®Œæˆ")
        print("ç‰¹ç‚¹: æ— éœ€åˆ‡æ¢çª—å£ï¼Œæ‰€æœ‰æ§åˆ¶åœ¨ä¸€ä¸ªç•Œé¢å®Œæˆ")
        
    def connect(self):
        """è¿æ¥AirSim"""
        try:
            print("æ­£åœ¨è¿æ¥AirSim...")
            self.client.confirmConnection()
            print("AirSimè¿æ¥ç¡®è®¤æˆåŠŸ")
            
            print("å¯ç”¨APIæ§åˆ¶...")
            self.client.enableApiControl(True, vehicle_name="Drone1")
            print("APIæ§åˆ¶å¯ç”¨æˆåŠŸ")
            
            print("è§£é”æ— äººæœº...")
            self.client.armDisarm(True, vehicle_name="Drone1")
            print("æ— äººæœºè§£é”æˆåŠŸ")
            
            # æµ‹è¯•å›¾åƒè·å–
            print("æµ‹è¯•å›¾åƒè·å–...")
            test_request = airsim.ImageRequest("front_center", airsim.ImageType.Scene, False, False)
            test_response = self.client.simGetImages([test_request], vehicle_name="Drone1")[0]
            if test_response.image_data_uint8:
                print(f"å›¾åƒè·å–æµ‹è¯•æˆåŠŸ: {test_response.width}x{test_response.height}")
            else:
                print("è­¦å‘Š: å›¾åƒè·å–æµ‹è¯•å¤±è´¥")
            
            self.is_connected = True
            print("âœ… AirSimè¿æ¥å®Œå…¨æˆåŠŸ")
            return True
        except Exception as e:
            print(f"âŒ AirSimè¿æ¥å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
            
    def get_sensor_data(self):
        """è·å–ä¼ æ„Ÿå™¨æ•°æ®"""
        if not self.is_connected:
            return None
            
        try:
            # è·å–RGBå›¾åƒç”¨äºæ˜¾ç¤º
            rgb_request = airsim.ImageRequest("front_center", airsim.ImageType.Scene, False, False)
            rgb_response = self.client.simGetImages([rgb_request], vehicle_name="Drone1")[0]
            
            # è·å–æ·±åº¦å›¾åƒç”¨äºè®­ç»ƒ
            depth_request = airsim.ImageRequest("front_center", airsim.ImageType.DepthPerspective, True, False)
            depth_response = self.client.simGetImages([depth_request], vehicle_name="Drone1")[0]
            
            # å¤„ç†RGBå›¾åƒ
            rgb_array = None
            if rgb_response.image_data_uint8 and len(rgb_response.image_data_uint8) > 0:
                rgb_1d = np.frombuffer(rgb_response.image_data_uint8, dtype=np.uint8)
                if len(rgb_1d) >= rgb_response.height * rgb_response.width * 3:
                    rgb_array = rgb_1d.reshape(rgb_response.height, rgb_response.width, 3)
                    rgb_array = cv2.resize(rgb_array, self.display_size)
                    # BGRè½¬RGB (OpenCVé»˜è®¤BGR)
                    rgb_array = cv2.cvtColor(rgb_array, cv2.COLOR_BGR2RGB)
            
            # å¦‚æœRGBå¤±è´¥ï¼Œåˆ›å»ºé»˜è®¤å›¾åƒ
            if rgb_array is None:
                print("è­¦å‘Š: RGBå›¾åƒè·å–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å›¾åƒ")
                rgb_array = np.zeros((self.display_size[1], self.display_size[0], 3), dtype=np.uint8)
                cv2.putText(rgb_array, "No Camera Feed", (50, self.display_size[1]//2), 
                           cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
            
            # å¤„ç†æ·±åº¦å›¾åƒ
            depth_array = None
            if depth_response.image_data_float and len(depth_response.image_data_float) > 0:
                depth_1d = np.array(depth_response.image_data_float, dtype=np.float32)
                if len(depth_1d) >= depth_response.height * depth_response.width:
                    depth_array = depth_1d.reshape(depth_response.height, depth_response.width)
                    depth_array = cv2.resize(depth_array, (self.image_size[1], self.image_size[0]))
                    depth_array = np.clip(depth_array, 0, 100) / 100.0
            
            # å¦‚æœæ·±åº¦å¤±è´¥ï¼Œåˆ›å»ºé»˜è®¤æ·±åº¦
            if depth_array is None:
                print("è­¦å‘Š: æ·±åº¦å›¾åƒè·å–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ·±åº¦")
                depth_array = np.ones(self.image_size, dtype=np.float32) * 0.5
                
            # è·å–æ— äººæœºçŠ¶æ€
            state = self.client.getMultirotorState(vehicle_name="Drone1")
            pose = state.kinematics_estimated.pose
            velocity = state.kinematics_estimated.linear_velocity
            
            return {
                'rgb_image': rgb_array,
                'depth_image': depth_array,
                'position': np.array([pose.position.x_val, pose.position.y_val, pose.position.z_val]),
                'quaternion': np.array([pose.orientation.w_val, pose.orientation.x_val, 
                                      pose.orientation.y_val, pose.orientation.z_val]),
                'velocity': np.array([velocity.x_val, velocity.y_val, velocity.z_val]),
                'timestamp': time.time()
            }
            
        except Exception as e:
            print(f"ä¼ æ„Ÿå™¨æ•°æ®è·å–å¤±è´¥: {e}")
            return None
            
    def create_control_overlay(self, image, sensor_data):
        """åˆ›å»ºæ§åˆ¶ç•Œé¢è¦†ç›–"""
        overlay = image.copy()
        h, w = overlay.shape[:2]
        
        # åŠé€æ˜èƒŒæ™¯
        cv2.rectangle(overlay, (10, 10), (w-10, 180), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.7, image, 0.3, 0, overlay)
        
        # æ ‡é¢˜
        cv2.putText(overlay, "ViT Data Collector", (20, 35), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)
        
        # è¿æ¥çŠ¶æ€
        status_color = (0, 255, 0) if self.is_connected else (0, 0, 255)
        status_text = "Connected" if self.is_connected else "Disconnected"
        cv2.putText(overlay, f"Status: {status_text}", (20, 60), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, status_color, 1)
        
        # æ”¶é›†çŠ¶æ€
        collect_color = (0, 255, 0) if self.is_collecting else (255, 255, 255)
        collect_text = "COLLECTING" if self.is_collecting else "Stopped"
        cv2.putText(overlay, f"Recording: {collect_text}", (20, 80), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, collect_color, 1)
        
        # ç»Ÿè®¡ä¿¡æ¯
        if sensor_data:
            vel = sensor_data['velocity']
            speed = np.linalg.norm(vel)
            cv2.putText(overlay, f"Speed: {speed:.2f} m/s", (20, 100), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
            
        cv2.putText(overlay, f"Trajectories: {self.trajectory_count}", (20, 120), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        cv2.putText(overlay, f"Samples: {len(self.current_trajectory)}", (20, 140), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        # æ§åˆ¶è¯´æ˜
        controls = [
            "Controls (Press keys in this window):",
            "W/S: Forward/Backward  A/D: Left/Right",
            "Q/E: Up/Down  X: Stop  SPACE: Record",
            "ESC: Exit"
        ]
        
        for i, text in enumerate(controls):
            y_pos = h - 80 + (i * 20)
            cv2.putText(overlay, text, (20, y_pos), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 0), 1)
        
        return overlay
        
    def handle_key_input(self, key):
        """å¤„ç†æŒ‰é”®è¾“å…¥"""
        base_speed = 2.0
        
        if key == ord('w') or key == ord('W'):
            self.command_queue.put(('move', [base_speed, 0, 0]))
            print("å‰è¿›")
        elif key == ord('s') or key == ord('S'):
            self.command_queue.put(('move', [-base_speed, 0, 0]))
            print("åé€€")
        elif key == ord('a') or key == ord('A'):
            self.command_queue.put(('move', [0, -base_speed, 0]))
            print("å·¦ç§»")
        elif key == ord('d') or key == ord('D'):
            self.command_queue.put(('move', [0, base_speed, 0]))
            print("å³ç§»")
        elif key == ord('q') or key == ord('Q'):
            self.command_queue.put(('move', [0, 0, -base_speed]))
            print("ä¸Šå‡")
        elif key == ord('e') or key == ord('E'):
            self.command_queue.put(('move', [0, 0, base_speed]))
            print("ä¸‹é™")
        elif key == ord('x') or key == ord('X'):
            self.command_queue.put(('move', [0, 0, 0]))
            print("åœæ­¢")
        elif key == ord(' '):  # ç©ºæ ¼é”®
            self.toggle_collection()
        elif key == 27:  # ESCé”®
            return False
            
        return True
        
    def toggle_collection(self):
        """åˆ‡æ¢æ•°æ®æ”¶é›†çŠ¶æ€"""
        if self.is_collecting:
            self.stop_collection()
        else:
            self.start_collection()
            
    def start_collection(self):
        """å¼€å§‹æ•°æ®æ”¶é›†"""
        self.is_collecting = True
        self.current_trajectory = []
        print(f"ğŸŸ¢ å¼€å§‹æ”¶é›†è½¨è¿¹ {self.trajectory_count}")
        
    def stop_collection(self):
        """åœæ­¢æ•°æ®æ”¶é›†"""
        if self.is_collecting and len(self.current_trajectory) > 0:
            self.save_trajectory()
            self.trajectory_count += 1
            
        self.is_collecting = False
        print("ğŸ”´ æ•°æ®æ”¶é›†å·²åœæ­¢")
        
    def execute_commands(self):
        """æ‰§è¡Œè¿åŠ¨æŒ‡ä»¤"""
        try:
            while not self.command_queue.empty():
                command, params = self.command_queue.get_nowait()
                if command == 'move' and self.is_connected:
                    vx, vy, vz = params
                    self.client.moveByVelocityAsync(
                        float(vx), float(vy), float(vz), 0.1,
                        vehicle_name="Drone1"
                    )
        except queue.Empty:
            pass
            
    def collect_sample(self, sensor_data):
        """æ”¶é›†æ•°æ®æ ·æœ¬"""
        if not self.is_collecting or not sensor_data:
            return
            
        try:
            collision_info = self.client.simGetCollisionInfo(vehicle_name="Drone1")
            
            sample = {
                'depth_image': sensor_data['depth_image'],
                'position': sensor_data['position'],
                'quaternion': sensor_data['quaternion'],
                'current_velocity': sensor_data['velocity'],
                'desired_velocity': 2.0,
                'velocity_command': sensor_data['velocity'].copy(),
                'collision': collision_info.has_collided,
                'timestamp': sensor_data['timestamp']
            }
            
            self.current_trajectory.append(sample)
            
        except Exception as e:
            pass
            
    def save_trajectory(self):
        """ä¿å­˜è½¨è¿¹æ•°æ®"""
        if len(self.current_trajectory) < 10:
            print("è½¨è¿¹å¤ªçŸ­ï¼Œè·³è¿‡ä¿å­˜")
            return
            
        traj_dir = self.data_dir / f"trajectory_{self.trajectory_count:06d}"
        traj_dir.mkdir(exist_ok=True)
        
        metadata = []
        for i, sample in enumerate(self.current_trajectory):
            # ä¿å­˜æ·±åº¦å›¾åƒ
            depth_img = (sample['depth_image'] * 255).astype(np.uint8)
            img_path = traj_dir / f"depth_{i:06d}.png"
            cv2.imwrite(str(img_path), depth_img)
            
            # å…ƒæ•°æ®
            metadata.append({
                'frame_id': i,
                'timestamp': sample['timestamp'],
                'pos_x': sample['position'][0],
                'pos_y': sample['position'][1], 
                'pos_z': sample['position'][2],
                'quat_w': sample['quaternion'][0],
                'quat_x': sample['quaternion'][1],
                'quat_y': sample['quaternion'][2],
                'quat_z': sample['quaternion'][3],
                'vel_x': sample['current_velocity'][0],
                'vel_y': sample['current_velocity'][1],
                'vel_z': sample['current_velocity'][2],
                'desired_vel': sample['desired_velocity'],
                'cmd_vx': sample['velocity_command'][0],
                'cmd_vy': sample['velocity_command'][1],
                'cmd_vz': sample['velocity_command'][2],
                'collision': sample['collision']
            })
            
        df = pd.DataFrame(metadata)
        df.to_csv(traj_dir / "data.csv", index=False)
        print(f"âœ… è½¨è¿¹ {self.trajectory_count} å·²ä¿å­˜: {len(self.current_trajectory)} æ ·æœ¬")
        
    def run_collection(self):
        """è¿è¡Œæ•°æ®æ”¶é›†ä¸»å¾ªç¯"""
        if not self.connect():
            return
            
        print("\nğŸš è¦†ç›–æ˜¾ç¤ºæ•°æ®æ”¶é›†å™¨å¯åŠ¨!")
        print("æ‰€æœ‰æ§åˆ¶åœ¨å¼¹å‡ºçš„å›¾åƒçª—å£ä¸­å®Œæˆï¼Œæ— éœ€åˆ‡æ¢")
        print("ç¡®ä¿å›¾åƒçª—å£è·å¾—ç„¦ç‚¹åæŒ‰é”®æ§åˆ¶")
        
        dt = 1.0 / self.collection_frequency
        
        try:
            while self.running:
                loop_start = time.time()
                
                # è·å–ä¼ æ„Ÿå™¨æ•°æ®
                sensor_data = self.get_sensor_data()
                
                if sensor_data:
                    # åˆ›å»ºæ§åˆ¶ç•Œé¢
                    display_image = self.create_control_overlay(
                        sensor_data['rgb_image'], sensor_data
                    )
                    
                    # æ˜¾ç¤ºå›¾åƒ
                    cv2.imshow(self.window_name, display_image)
                    
                    # å¤„ç†æŒ‰é”®ï¼ˆç­‰å¾…1msï¼‰
                    key = cv2.waitKey(1) & 0xFF
                    if key != 255:  # æœ‰æŒ‰é”®
                        if not self.handle_key_input(key):
                            break
                    
                    # æ‰§è¡Œè¿åŠ¨æŒ‡ä»¤
                    self.execute_commands()
                    
                    # æ”¶é›†æ•°æ®
                    self.collect_sample(sensor_data)
                    
                else:
                    # æ— ä¼ æ„Ÿå™¨æ•°æ®æ—¶æ˜¾ç¤ºè¿æ¥ç•Œé¢
                    blank = np.zeros((300, 400, 3), dtype=np.uint8)
                    cv2.putText(blank, "Connecting to AirSim...", (50, 150), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)
                    cv2.imshow(self.window_name, blank)
                    cv2.waitKey(1)
                
                # æ§åˆ¶é¢‘ç‡
                elapsed = time.time() - loop_start
                if elapsed < dt:
                    time.sleep(dt - elapsed)
                    
        except KeyboardInterrupt:
            print("\næ”¶åˆ°ä¸­æ–­ä¿¡å·")
        finally:
            self.cleanup()
            
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        self.running = False
        if self.is_collecting:
            self.stop_collection()
        if self.is_connected:
            try:
                self.client.armDisarm(False, vehicle_name="Drone1")
                self.client.enableApiControl(False, vehicle_name="Drone1")
            except:
                pass
        cv2.destroyAllWindows()
        print(f"æ•°æ®æ”¶é›†ç»“æŸï¼Œå…±æ”¶é›† {self.trajectory_count} æ¡è½¨è¿¹")


def main():
    """ä¸»å‡½æ•°"""
    collector = OverlayDataCollector()
    collector.run_collection()


if __name__ == "__main__":
    main()