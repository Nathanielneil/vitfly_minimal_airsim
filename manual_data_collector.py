#!/usr/bin/env python3
"""
æ‰‹åŠ¨APIæ§åˆ¶æ•°æ®æ”¶é›†å™¨
ä½¿ç”¨ç¨‹åºå†…ç½®æ§åˆ¶ä»£æ›¿AirSimé”®ç›˜æ§åˆ¶
"""

import airsim
import numpy as np
import cv2
import time
import os
import pandas as pd
import msvcrt  # Windowsé”®ç›˜è¾“å…¥
from pathlib import Path


class ManualDataCollector:
    """æ‰‹åŠ¨APIæ§åˆ¶æ•°æ®æ”¶é›†å™¨"""
    
    def __init__(self, data_dir="./training_data"):
        self.client = airsim.MultirotorClient()
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(exist_ok=True)
        
        # æ”¶é›†å‚æ•°
        self.collection_frequency = 10
        self.image_size = (60, 90)
        self.base_speed = 2.0
        
        # çŠ¶æ€
        self.is_collecting = False
        self.current_trajectory = []
        self.trajectory_count = 0
        self.current_velocity_cmd = np.array([0.0, 0.0, 0.0])
        
        print("æ‰‹åŠ¨APIæ§åˆ¶æ•°æ®æ”¶é›†å™¨åˆå§‹åŒ–å®Œæˆ")
        print("\næ§åˆ¶è¯´æ˜:")
        print("  W/S: å‰è¿›/åé€€")
        print("  A/D: å·¦ç§»/å³ç§»")
        print("  Q/E: ä¸Šå‡/ä¸‹é™")
        print("  SPACE: å¼€å§‹/åœæ­¢æ•°æ®æ”¶é›†")
        print("  X: åœæ­¢ç§»åŠ¨")
        print("  ESC: é€€å‡ºç¨‹åº")
        print("\næ³¨æ„: è¯·ä¿æŒæ­¤ç»ˆç«¯çª—å£ä¸ºæ´»åŠ¨çª—å£ä»¥æ¥æ”¶æŒ‰é”®è¾“å…¥")
        
    def connect(self):
        """è¿æ¥AirSim"""
        try:
            self.client.confirmConnection()
            self.client.enableApiControl(True, vehicle_name="Drone1")
            self.client.armDisarm(True, vehicle_name="Drone1")
            print("AirSimè¿æ¥æˆåŠŸï¼ŒAPIæ§åˆ¶å·²å¯ç”¨")
            return True
        except Exception as e:
            print(f"AirSimè¿æ¥å¤±è´¥: {e}")
            return False
            
    def get_sensor_data(self):
        """è·å–ä¼ æ„Ÿå™¨æ•°æ®"""
        try:
            # è·å–æ·±åº¦å›¾åƒ
            request = airsim.ImageRequest("front_center", airsim.ImageType.DepthPerspective, True, False)
            response = self.client.simGetImages([request])[0]
            
            if response.image_data_float:
                depth_array = np.array(response.image_data_float, dtype=np.float32)
                depth_array = depth_array.reshape(response.height, response.width)
                depth_image = cv2.resize(depth_array, (self.image_size[1], self.image_size[0]))
                depth_image = np.clip(depth_image, 0, 100) / 100.0
            else:
                return None
                
            # è·å–æ— äººæœºçŠ¶æ€
            state = self.client.getMultirotorState()
            pose = state.kinematics_estimated.pose
            velocity = state.kinematics_estimated.linear_velocity
            
            return {
                'depth_image': depth_image,
                'position': np.array([pose.position.x_val, pose.position.y_val, pose.position.z_val]),
                'quaternion': np.array([pose.orientation.w_val, pose.orientation.x_val, 
                                      pose.orientation.y_val, pose.orientation.z_val]),
                'velocity': np.array([velocity.x_val, velocity.y_val, velocity.z_val]),
                'timestamp': time.time()
            }
            
        except Exception as e:
            return None
            
    def handle_keyboard_input(self):
        """å¤„ç†é”®ç›˜è¾“å…¥ï¼ˆWindowsç‰ˆæœ¬ï¼‰"""
        if msvcrt.kbhit():
            key = msvcrt.getch().decode('utf-8').lower()
            
            if key == 'w':
                self.current_velocity_cmd = np.array([self.base_speed, 0, 0])
                print("å‰è¿›")
            elif key == 's':
                self.current_velocity_cmd = np.array([-self.base_speed, 0, 0])
                print("åé€€")
            elif key == 'a':
                self.current_velocity_cmd = np.array([0, -self.base_speed, 0])
                print("å·¦ç§»")
            elif key == 'd':
                self.current_velocity_cmd = np.array([0, self.base_speed, 0])
                print("å³ç§»")
            elif key == 'q':
                self.current_velocity_cmd = np.array([0, 0, -self.base_speed])
                print("ä¸Šå‡")
            elif key == 'e':
                self.current_velocity_cmd = np.array([0, 0, self.base_speed])
                print("ä¸‹é™")
            elif key == 'x':
                self.current_velocity_cmd = np.array([0, 0, 0])
                print("åœæ­¢")
            elif key == ' ':  # ç©ºæ ¼é”®
                self.toggle_collection()
            elif key == '\x1b':  # ESCé”®
                return False
                
        return True
        
    def toggle_collection(self):
        """åˆ‡æ¢æ•°æ®æ”¶é›†çŠ¶æ€"""
        if self.is_collecting:
            self.stop_collection()
        else:
            self.start_collection()
            
    def start_collection(self):
        """å¼€å§‹æ•°æ®æ”¶é›†"""
        self.is_collecting = True
        self.current_trajectory = []
        print(f"\nğŸŸ¢ å¼€å§‹æ”¶é›†è½¨è¿¹ {self.trajectory_count}")
        
    def stop_collection(self):
        """åœæ­¢æ•°æ®æ”¶é›†"""
        if self.is_collecting and len(self.current_trajectory) > 0:
            self.save_trajectory()
            self.trajectory_count += 1
            
        self.is_collecting = False
        print("ğŸ”´ æ•°æ®æ”¶é›†å·²åœæ­¢")
        
    def collect_sample(self):
        """æ”¶é›†æ•°æ®æ ·æœ¬"""
        sensor_data = self.get_sensor_data()
        if sensor_data is None:
            return
            
        # æ‰§è¡Œé€Ÿåº¦æŒ‡ä»¤
        if np.any(self.current_velocity_cmd != 0):
            self.client.moveByVelocityAsync(
                float(self.current_velocity_cmd[0]),
                float(self.current_velocity_cmd[1]),
                float(self.current_velocity_cmd[2]),
                0.1
            )
        
        # æ”¶é›†æ•°æ®
        if self.is_collecting:
            collision_info = self.client.simGetCollisionInfo()
            
            sample = {
                'depth_image': sensor_data['depth_image'],
                'position': sensor_data['position'],
                'quaternion': sensor_data['quaternion'],
                'current_velocity': sensor_data['velocity'],
                'desired_velocity': 2.0,
                'velocity_command': self.current_velocity_cmd.copy(),
                'collision': collision_info.has_collided,
                'timestamp': sensor_data['timestamp']
            }
            
            self.current_trajectory.append(sample)
            
            if len(self.current_trajectory) % 20 == 0:
                print(f"å·²æ”¶é›† {len(self.current_trajectory)} ä¸ªæ ·æœ¬")
                
    def save_trajectory(self):
        """ä¿å­˜è½¨è¿¹æ•°æ®"""
        if len(self.current_trajectory) < 10:
            print("è½¨è¿¹å¤ªçŸ­ï¼Œè·³è¿‡ä¿å­˜")
            return
            
        # åˆ›å»ºè½¨è¿¹æ–‡ä»¶å¤¹
        traj_dir = self.data_dir / f"trajectory_{self.trajectory_count:06d}"
        traj_dir.mkdir(exist_ok=True)
        
        # ä¿å­˜æ•°æ®
        metadata = []
        
        for i, sample in enumerate(self.current_trajectory):
            # ä¿å­˜æ·±åº¦å›¾åƒ
            depth_img = (sample['depth_image'] * 255).astype(np.uint8)
            img_path = traj_dir / f"depth_{i:06d}.png"
            cv2.imwrite(str(img_path), depth_img)
            
            # æ”¶é›†å…ƒæ•°æ®
            metadata.append({
                'frame_id': i,
                'timestamp': sample['timestamp'],
                'pos_x': sample['position'][0],
                'pos_y': sample['position'][1], 
                'pos_z': sample['position'][2],
                'quat_w': sample['quaternion'][0],
                'quat_x': sample['quaternion'][1],
                'quat_y': sample['quaternion'][2],
                'quat_z': sample['quaternion'][3],
                'vel_x': sample['current_velocity'][0],
                'vel_y': sample['current_velocity'][1],
                'vel_z': sample['current_velocity'][2],
                'desired_vel': sample['desired_velocity'],
                'cmd_vx': sample['velocity_command'][0],
                'cmd_vy': sample['velocity_command'][1],
                'cmd_vz': sample['velocity_command'][2],
                'collision': sample['collision']
            })
            
        # ä¿å­˜CSV
        df = pd.DataFrame(metadata)
        df.to_csv(traj_dir / "data.csv", index=False)
        
        print(f"âœ… è½¨è¿¹ {self.trajectory_count} å·²ä¿å­˜: {len(self.current_trajectory)} æ ·æœ¬")
        
    def run_collection(self):
        """è¿è¡Œæ•°æ®æ”¶é›†ä¸»å¾ªç¯"""
        if not self.connect():
            return
            
        print("\nğŸš æ‰‹åŠ¨æ§åˆ¶æ•°æ®æ”¶é›†å¼€å§‹!")
        print("è¯·åœ¨æ­¤ç»ˆç«¯ä¸­æŒ‰é”®æ§åˆ¶æ— äººæœº")
        
        dt = 1.0 / self.collection_frequency
        
        try:
            while True:
                loop_start = time.time()
                
                # å¤„ç†é”®ç›˜è¾“å…¥
                if not self.handle_keyboard_input():
                    break
                    
                # æ”¶é›†æ•°æ®
                self.collect_sample()
                
                # æ§åˆ¶é¢‘ç‡
                elapsed = time.time() - loop_start
                if elapsed < dt:
                    time.sleep(dt - elapsed)
                    
        except KeyboardInterrupt:
            print("\næ”¶åˆ°ä¸­æ–­ä¿¡å·")
        finally:
            self.stop_collection()
            self.client.armDisarm(False)
            self.client.enableApiControl(False)
            print(f"æ•°æ®æ”¶é›†ç»“æŸï¼Œå…±æ”¶é›† {self.trajectory_count} æ¡è½¨è¿¹")


def main():
    """ä¸»å‡½æ•°"""
    collector = ManualDataCollector()
    collector.run_collection()


if __name__ == "__main__":
    main()