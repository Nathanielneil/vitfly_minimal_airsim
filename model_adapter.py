"""
æ¨¡å‹æƒé‡é€‚é…å™¨ - å°†åŸå§‹ViTflyæƒé‡é€‚é…åˆ°æœ€å°å®ç°
"""

import torch
import torch.nn as nn
import numpy as np
from vit_model import create_minimal_vit_model


def create_dummy_weights():
    """åˆ›å»ºè™šæ‹Ÿçš„é¢„è®­ç»ƒæƒé‡ç”¨äºæµ‹è¯•"""
    model = create_minimal_vit_model()
    
    # åˆå§‹åŒ–æƒé‡ä¸ºæ›´åˆç†çš„å€¼
    for module in model.modules():
        if isinstance(module, nn.Linear):
            nn.init.xavier_uniform_(module.weight)
            if module.bias is not None:
                nn.init.zeros_(module.bias)
        elif isinstance(module, nn.Conv2d):
            nn.init.kaiming_normal_(module.weight, mode='fan_out', nonlinearity='relu')
        elif isinstance(module, nn.LSTM):
            for name, param in module.named_parameters():
                if 'weight' in name:
                    nn.init.orthogonal_(param)
                elif 'bias' in name:
                    nn.init.zeros_(param)
    
    # ä¿å­˜è™šæ‹Ÿæƒé‡
    torch.save(model.state_dict(), 'vitfly_dummy_weights.pth')
    print("å·²åˆ›å»ºè™šæ‹Ÿé¢„è®­ç»ƒæƒé‡: vitfly_dummy_weights.pth")
    
    return model


def adapt_original_vitfly_weights(original_model_path: str, output_path: str = 'vitfly_adapted_weights.pth'):
    """
    é€‚é…åŸå§‹ViTflyæ¨¡å‹æƒé‡åˆ°æˆ‘ä»¬çš„æœ€å°å®ç°
    
    Args:
        original_model_path: åŸå§‹ViTflyæ¨¡å‹æƒé‡è·¯å¾„
        output_path: è¾“å‡ºé€‚é…åæƒé‡çš„è·¯å¾„
    """
    try:
        # åŠ è½½åŸå§‹æƒé‡
        original_weights = torch.load(original_model_path, map_location='cpu')
        print(f"åŸå§‹æ¨¡å‹æƒé‡é”®: {list(original_weights.keys())}")
        
        # åˆ›å»ºæˆ‘ä»¬çš„æ¨¡å‹
        our_model = create_minimal_vit_model()
        our_state_dict = our_model.state_dict()
        print(f"æˆ‘ä»¬çš„æ¨¡å‹æƒé‡é”®: {list(our_state_dict.keys())}")
        
        # æƒé‡æ˜ å°„å­—å…¸
        weight_mapping = {
            # ç¤ºä¾‹æ˜ å°„ - éœ€è¦æ ¹æ®å®é™…çš„åŸå§‹æ¨¡å‹ç»“æ„è°ƒæ•´
            'patch_embed.proj.weight': 'patch_embed.proj.weight',
            'patch_embed.proj.bias': 'patch_embed.proj.bias',
            'patch_embed.norm.weight': 'patch_embed.norm.weight',
            'patch_embed.norm.bias': 'patch_embed.norm.bias',
            
            # Transformerå±‚æ˜ å°„
            'transformer_layers.0.attn.q_proj.weight': 'encoder_blocks.0.attn.q_proj.weight',
            'transformer_layers.0.attn.kv_proj.weight': 'encoder_blocks.0.attn.kv_proj.weight',
            
            # LSTMæ˜ å°„
            'lstm.weight_ih_l0': 'lstm.weight_ih_l0',
            'lstm.weight_hh_l0': 'lstm.weight_hh_l0',
            'lstm.bias_ih_l0': 'lstm.bias_ih_l0',
            'lstm.bias_hh_l0': 'lstm.bias_hh_l0',
            
            # è¾“å‡ºå±‚æ˜ å°„
            'velocity_head.0.weight': 'nn_fc2.weight',
            'velocity_head.0.bias': 'nn_fc2.bias',
        }
        
        # é€‚é…æƒé‡
        adapted_weights = {}
        
        for our_key, our_param in our_state_dict.items():
            if our_key in weight_mapping:
                original_key = weight_mapping[our_key]
                if original_key in original_weights:
                    original_param = original_weights[original_key]
                    
                    # æ£€æŸ¥å½¢çŠ¶å…¼å®¹æ€§
                    if our_param.shape == original_param.shape:
                        adapted_weights[our_key] = original_param
                        print(f"âœ… æˆåŠŸæ˜ å°„: {our_key} <- {original_key}")
                    else:
                        # å°è¯•å½¢çŠ¶é€‚é…
                        adapted_param = adapt_parameter_shape(our_param, original_param)
                        if adapted_param is not None:
                            adapted_weights[our_key] = adapted_param
                            print(f"ğŸ”„ å½¢çŠ¶é€‚é…: {our_key} {our_param.shape} <- {original_key} {original_param.shape}")
                        else:
                            adapted_weights[our_key] = our_param
                            print(f"âŒ å½¢çŠ¶ä¸åŒ¹é…ï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–: {our_key}")
                else:
                    adapted_weights[our_key] = our_param
                    print(f"â“ åŸå§‹æ¨¡å‹ä¸­æœªæ‰¾åˆ°å¯¹åº”æƒé‡ï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–: {our_key}")
            else:
                adapted_weights[our_key] = our_param
                print(f"â¡ï¸ ä½¿ç”¨éšæœºåˆå§‹åŒ–: {our_key}")
        
        # ä¿å­˜é€‚é…åçš„æƒé‡
        torch.save(adapted_weights, output_path)
        print(f"\nâœ… æƒé‡é€‚é…å®Œæˆï¼Œå·²ä¿å­˜åˆ°: {output_path}")
        
        return output_path
        
    except Exception as e:
        print(f"âŒ æƒé‡é€‚é…å¤±è´¥: {e}")
        return None


def adapt_parameter_shape(target_param: torch.Tensor, source_param: torch.Tensor) -> torch.Tensor:
    """å°è¯•é€‚é…å‚æ•°å½¢çŠ¶"""
    target_shape = target_param.shape
    source_shape = source_param.shape
    
    # å¦‚æœç»´åº¦ç›¸åŒï¼Œå°è¯•æˆªå–æˆ–å¡«å……
    if len(target_shape) == len(source_shape):
        adapted = source_param
        
        for dim in range(len(target_shape)):
            if target_shape[dim] != source_shape[dim]:
                if target_shape[dim] < source_shape[dim]:
                    # æˆªå–
                    slices = [slice(None)] * len(target_shape)
                    slices[dim] = slice(0, target_shape[dim])
                    adapted = adapted[tuple(slices)]
                else:
                    # å¡«å……
                    pad_size = target_shape[dim] - source_shape[dim]
                    pad_dims = [0] * (2 * len(target_shape))
                    pad_dims[-(2*dim+1)] = pad_size
                    adapted = torch.nn.functional.pad(adapted, pad_dims)
        
        return adapted
    
    return None


def create_simple_obstacle_avoidance_policy():
    """åˆ›å»ºç®€å•çš„é¿éšœç­–ç•¥æƒé‡ï¼ˆåŸºäºè§„åˆ™çš„åˆå§‹åŒ–ï¼‰"""
    model = create_minimal_vit_model()
    
    # ä¸ºæœ€ç»ˆçš„é€Ÿåº¦é¢„æµ‹å±‚è®¾ç½®æ›´ä¿å®ˆçš„åˆå§‹æƒé‡
    with torch.no_grad():
        # è®©æ¨¡å‹å€¾å‘äºè¾“å‡ºå‰è¿›+å¾®è°ƒçš„é€Ÿåº¦
        if hasattr(model, 'velocity_head'):
            final_layer = model.velocity_head[-1]  # æœ€åä¸€å±‚
            
            # å‰è¿›æ–¹å‘æƒé‡æ›´å¤§
            final_layer.weight[0, :] = torch.randn_like(final_layer.weight[0, :]) * 0.5 + 0.5  # vx: åå‘å‰è¿›
            final_layer.weight[1, :] = torch.randn_like(final_layer.weight[1, :]) * 0.2      # vy: å°å¹…å·¦å³
            final_layer.weight[2, :] = torch.randn_like(final_layer.weight[2, :]) * 0.1      # vz: è½»å¾®å‡é™
            
            # åç½®è®¾ç½®
            final_layer.bias[0] = 0.7   # é»˜è®¤å‰è¿›
            final_layer.bias[1] = 0.0   # ä¸åå‘å·¦å³
            final_layer.bias[2] = 0.0   # ä¿æŒé«˜åº¦
    
    # ä¿å­˜ç®€å•ç­–ç•¥æƒé‡
    torch.save(model.state_dict(), 'vitfly_simple_policy.pth')
    print("å·²åˆ›å»ºç®€å•é¿éšœç­–ç•¥æƒé‡: vitfly_simple_policy.pth")
    
    return model


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="ViTflyæ¨¡å‹æƒé‡é€‚é…å™¨")
    parser.add_argument('--mode', choices=['dummy', 'adapt', 'simple'], default='simple',
                       help='æ¨¡å¼: dummy(è™šæ‹Ÿæƒé‡), adapt(é€‚é…åŸå§‹æƒé‡), simple(ç®€å•ç­–ç•¥)')
    parser.add_argument('--original', type=str, help='åŸå§‹ViTflyæƒé‡è·¯å¾„')
    parser.add_argument('--output', type=str, help='è¾“å‡ºæƒé‡è·¯å¾„')
    
    args = parser.parse_args()
    
    if args.mode == 'dummy':
        create_dummy_weights()
    elif args.mode == 'adapt':
        if not args.original:
            print("âŒ éœ€è¦æŒ‡å®šåŸå§‹æƒé‡è·¯å¾„: --original <path>")
        else:
            output_path = args.output or 'vitfly_adapted_weights.pth'
            adapt_original_vitfly_weights(args.original, output_path)
    elif args.mode == 'simple':
        create_simple_obstacle_avoidance_policy()
    
    print("\nä½¿ç”¨æ–¹æ³•:")
    print("python vitfly_main.py --model vitfly_simple_policy.pth")